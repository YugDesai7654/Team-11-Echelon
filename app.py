import streamlit as st
import os
from PIL import Image
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import chat utilities
from src.utils.chat_utils import get_chat_response, is_groq_available

def set_custom_style():
    st.markdown("""
        <style>
        .main {
            padding-top: 2rem;
        }
        .stButton>button {
            width: 100%;
            background-color: #FF4B4B;
            color: white;
            font-weight: bold;
            border-radius: 8px;
            padding: 0.5rem 1rem;
        }
        .stButton>button:hover {
            background-color: #FF2B2B;
            color: white;
            border-color: #FF2B2B;
        }
        h1 {
            color: #FAFAFA;
            font-family: 'Helvetica Neue', sans-serif;
        }
        h3 {
            color: #E0E0E0;
        }
        .deliverable-card {
            background: linear-gradient(135deg, rgba(30, 30, 40, 0.9), rgba(40, 40, 55, 0.9));
            border-radius: 12px;
            padding: 20px;
            margin: 15px 0;
            border-left: 4px solid;
        }
        .deliverable-header {
            font-size: 1.1em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .metric-box {
            background: rgba(255,255,255,0.05);
            border-radius: 8px;
            padding: 12px;
            margin: 8px 0;
        }
        </style>
        """, unsafe_allow_html=True)


def display_deliverable_results(pipeline_result, has_image):
    """Display detailed results for each deliverable in sequence."""
    from src.pipeline.base import StageType
    
    st.markdown("---")
    st.markdown("## ğŸ“Š Pipeline Results by Deliverable")
    st.markdown("*Results from each of the 7 mandatory deliverables:*")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DELIVERABLE 1: Multi-modal Input Handling
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with st.expander("ğŸ“¥ **D1: Multi-Modal Input Handling** - Text + Image/Video Processing", expanded=True):
        input_result = pipeline_result.get_stage_result(StageType.INPUT_HANDLING)
        if input_result and input_result.success:
            data = input_result.data
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Text Length", f"{data.get('text_length', 0)} chars")
            with col2:
                st.metric("Has Image", "âœ… Yes" if data.get('has_image') else "âŒ No")
            with col3:
                st.metric("Modality", data.get('modality', 'unknown').upper())
            
            if data.get('has_image'):
                st.info(f"ğŸ“ Image: {data.get('image_width', 'N/A')}x{data.get('image_height', 'N/A')} ({data.get('image_mode', 'N/A')})")
            
            st.success(f"âœ… Completed in {input_result.execution_time_ms:.0f}ms")
        else:
            st.error("âŒ Input handling failed")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DELIVERABLE 2: Cross-Modal Inconsistency Detection
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with st.expander("ğŸ”— **D2: Cross-Modal Inconsistency Detection** - CLIP Text-Image Analysis", expanded=True):
        cross_modal_result = pipeline_result.get_stage_result(StageType.CROSS_MODAL_DETECTION)
        if cross_modal_result and cross_modal_result.success:
            data = cross_modal_result.data
            
            # Similarity gauge
            similarity = data.get('similarity', 0)
            verdict = data.get('verdict', 'N/A')
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("CLIP Similarity", f"{similarity:.4f}", 
                         delta="Aligned" if similarity > 0.25 else "Mismatched",
                         delta_color="normal" if similarity > 0.25 else "inverse")
            with col2:
                st.metric("Verdict", verdict)
            with col3:
                st.metric("Confidence", f"{data.get('confidence', 0):.1%}")
            
            # Visual indicator
            if similarity >= 0.30:
                st.success("âœ… **Consistent**: Caption and image are semantically aligned")
            elif similarity >= 0.25:
                st.warning("âš ï¸ **Possible Mismatch**: Weak alignment detected")
            else:
                st.error("ğŸš¨ **Inconsistent**: Caption does NOT match image content")
            
            st.markdown("**Explanation:**")
            st.info(data.get('explanation', 'N/A'))
            
            st.success(f"âœ… Completed in {cross_modal_result.execution_time_ms:.0f}ms")
        elif not has_image:
            st.info("â­ï¸ **Skipped**: No image provided for cross-modal analysis")
        else:
            st.error(f"âŒ Failed: {cross_modal_result.error if cross_modal_result else 'Unknown error'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DELIVERABLE 3: Out-of-Context Media Reuse Detection
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with st.expander("ğŸŒ **D3: Out-of-Context Media Detection** - Web Search Verification", expanded=True):
        context_result = pipeline_result.get_stage_result(StageType.CONTEXT_DETECTION)
        if context_result and context_result.success:
            data = context_result.data
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Context Score", f"{data.get('context_score', 0):.2f}")
            with col2:
                st.metric("Context Verdict", data.get('context_verdict', 'N/A'))
            
            # Context flags
            flags = data.get('context_flags', [])
            if flags:
                st.warning("ğŸš© **Flags Detected:**")
                for flag in flags:
                    st.markdown(f"- âš ï¸ {flag}")
            else:
                st.success("âœ… No context manipulation flags detected")
            
            # Search results
            search_results = data.get('search_results', {})
            if search_results.get('found'):
                st.markdown("**ğŸ” Web Search Results:**")
                for i, res in enumerate(search_results.get('results', [])[:3], 1):
                    st.markdown(f"{i}. [{res.get('title', 'N/A')[:50]}...]({res.get('url', '#')})")
            
            st.success(f"âœ… Completed in {context_result.execution_time_ms:.0f}ms")
        elif context_result is None:
            st.warning("â³ **Status: PENDING** - This deliverable is currently queued for implementation.")
        else:
            st.error(f"âŒ Failed: {context_result.error if context_result else 'Unknown error'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DELIVERABLE 4: AI-Generated Synthetic Media Detection
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with st.expander("ğŸ¤– **D4: Synthetic Media Detection** - AI-Generated Content Analysis", expanded=True):
        synthetic_result = pipeline_result.get_stage_result(StageType.SYNTHETIC_DETECTION)
        if synthetic_result and synthetic_result.success:
            data = synthetic_result.data
            
            st.markdown("#### ğŸ“ AI Text Detection")
            col1, col2, col3 = st.columns(3)
            with col1:
                ai_text_prob = data.get('ai_text_probability', 0)
                st.metric("AI Text Probability", f"{ai_text_prob:.1%}",
                         delta="Likely AI" if ai_text_prob > 0.5 else "Likely Human",
                         delta_color="inverse" if ai_text_prob > 0.5 else "normal")
            with col2:
                st.metric("Text Label", data.get('text_label', 'N/A'))
            with col3:
                st.metric("Raw Score", f"{data.get('text_detection', {}).get('raw_score', 0):.4f}")
            
            if has_image:
                st.markdown("#### ğŸ–¼ï¸ AI Image Detection (SigLIP)")
                if data.get('ai_image_detection') or data.get('image_detection'):
                    col1, col2 = st.columns(2)
                    with col1:
                        ai_img_prob = data.get('ai_image_probability', 0)
                        st.metric("AI Image Probability", f"{ai_img_prob:.1%}",
                                 delta="ğŸ¤– AI Generated" if data.get('is_ai_image') else "ğŸ“· Real Photo",
                                 delta_color="inverse" if data.get('is_ai_image') else "normal")
                    with col2:
                        is_ai = data.get('is_ai_image', False)
                        st.metric("Detection", "AI Generated" if is_ai else "Natural Image")
                else:
                    st.info("No AI image detection performed")
                
                st.markdown("#### ğŸ­ Deepfake Detection (ViT)")
                if data.get('deepfake_detection'):
                    col1, col2 = st.columns(2)
                    with col1:
                        df_prob = data.get('deepfake_probability', 0)
                        st.metric("Deepfake Probability", f"{df_prob:.1%}",
                                 delta="ğŸš¨ Deepfake" if data.get('is_deepfake') else "âœ… Authentic",
                                 delta_color="inverse" if data.get('is_deepfake') else "normal")
                    with col2:
                        is_df = data.get('is_deepfake', False)
                        st.metric("Face Analysis", "Manipulated" if is_df else "Real Face")
                    
                    if data.get('is_deepfake'):
                        st.error("ğŸš¨ **Warning**: This image may contain face manipulation or deepfake content!")
                else:
                    st.info("â„¹ï¸ Deepfake detection not available")
                
                # Combined artifacts
                artifacts = data.get('image_artifacts', [])
                if artifacts:
                    st.warning("**ğŸ” Detected Artifacts:**")
                    for artifact in artifacts[:5]:
                        st.markdown(f"- {artifact}")
            
            st.markdown("#### ğŸ“Š Overall Synthetic Score")
            overall = data.get('overall_synthetic_score', 0)
            st.progress(overall)
            st.caption(f"Combined synthetic probability: {overall:.1%}")
            
            st.success(f"âœ… Completed in {synthetic_result.execution_time_ms:.0f}ms")
        else:
            st.error(f"âŒ Failed: {synthetic_result.error if synthetic_result else 'Unknown error'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DELIVERABLE 5: Natural Language Explanation Generation
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with st.expander("ğŸ“– **D5: Explanation Generation** - Natural Language Analysis", expanded=True):
        explanation_result = pipeline_result.get_stage_result(StageType.EXPLANATION_GENERATION)
        if explanation_result and explanation_result.success:
            data = explanation_result.data
            
            # Verdict box
            verdict = data.get('verdict', 'Unverified')
            score = data.get('truthfulness_score', 0)
            
            if score >= 80:
                verdict_color = "#00C853"
            elif score >= 50:
                verdict_color = "#FFB300"
            else:
                verdict_color = "#FF5252"
            
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, {verdict_color}22, {verdict_color}11); 
                        border-left: 4px solid {verdict_color}; padding: 15px; border-radius: 8px;">
                <h3 style="margin:0; color:{verdict_color};">âš–ï¸ VERDICT: {verdict.upper()}</h3>
                <p style="margin:5px 0 0 0;">Truthfulness Score: <strong>{score}/100</strong></p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("#### ğŸ“ Generated Explanation")
            st.info(data.get('explanation', 'No explanation provided.'))
            
            evidence = data.get('evidence', [])
            if evidence:
                st.markdown("#### ğŸ“‹ Evidence Points")
                for i, e in enumerate(evidence, 1):
                    st.markdown(f"{i}. {e}")
            
            st.success(f"âœ… Completed in {explanation_result.execution_time_ms:.0f}ms")
        else:
            st.error(f"âŒ Failed: {explanation_result.error if explanation_result else 'Unknown error'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DELIVERABLE 6: Robustness Against Adversarial Perturbations
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with st.expander("ğŸ›¡ï¸ **D6: Robustness Check** - Adversarial Defense Analysis", expanded=False):
        robustness_result = pipeline_result.get_stage_result(StageType.ROBUSTNESS_CHECK)
        if robustness_result and robustness_result.success:
            data = robustness_result.data
            
            col1, col2 = st.columns(2)
            with col1:
                rob_score = data.get('robustness_score', 0)
                st.metric("Robustness Score", f"{rob_score:.1%}",
                         delta="Secure" if rob_score > 0.8 else "Potential Issues",
                         delta_color="normal" if rob_score > 0.8 else "inverse")
            with col2:
                is_adv = data.get('is_adversarial_likely', False)
                st.metric("Adversarial Detected", "ğŸš¨ Yes" if is_adv else "âœ… No")
            
            flags = data.get('adversarial_flags', [])
            if flags:
                st.error("**ğŸš© Adversarial Flags:**")
                for flag in flags:
                    st.markdown(f"- âš ï¸ {flag}")
            else:
                st.success("âœ… Input appears clean - no adversarial patterns detected")
            
            st.markdown("**Security Checks:**")
            st.markdown("- âœ… Zero-width characters: Clean")
            st.markdown("- âœ… Homoglyph attacks: Clean")  
            st.markdown("- âœ… Prompt injection: Clean")
            
            st.success(f"âœ… Completed in {robustness_result.execution_time_ms:.0f}ms")
        elif robustness_result is None:
            st.warning("â³ **Status: PENDING** - This deliverable is currently queued for implementation.")
        else:
            st.error(f"âŒ Failed: {robustness_result.error if robustness_result else 'Unknown error'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DELIVERABLE 7: Quantitative Evaluation
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with st.expander("ğŸ“ˆ **D7: Quantitative Evaluation** - Performance Metrics", expanded=False):
        eval_result = pipeline_result.get_stage_result(StageType.EVALUATION)
        if eval_result and eval_result.success:
            data = eval_result.data
            metrics = data.get('metrics', {})
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Robustness", f"{metrics.get('robustness_score', 0):.1%}")
            with col2:
                st.metric("Explanation Quality", f"{metrics.get('explanation_quality', 0):.1%}")
            with col3:
                st.metric("Overall Score", f"{metrics.get('overall_score', 0):.1%}")
            
            # Component scores
            component = metrics.get('component_scores', {})
            if component:
                st.markdown("**Component Scores:**")
                for name, score in component.items():
                    st.progress(score)
                    st.caption(f"{name}: {score:.1%}")
            
            st.success(f"âœ… Completed in {eval_result.execution_time_ms:.0f}ms")
        elif eval_result is None:
            st.warning("â³ **Status: PENDING** - This deliverable is currently queued for implementation.")
        else:
            st.error(f"âŒ Failed: {eval_result.error if eval_result else 'Unknown error'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EXECUTION SUMMARY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    st.markdown("---")
    st.markdown("### â±ï¸ Execution Summary")
    
    exec_data = []
    stage_map = [
        (StageType.INPUT_HANDLING, "D1: Input Handling", "ğŸ“¥"),
        (StageType.SYNTHETIC_DETECTION, "D4: Synthetic Detection", "ğŸ¤–"),
        (StageType.CROSS_MODAL_DETECTION, "D2: Cross-Modal", "ğŸ”—"),
        (StageType.CONTEXT_DETECTION, "D3: Context Detection", "ğŸŒ"),
        (StageType.ROBUSTNESS_CHECK, "D6: Robustness", "ğŸ›¡ï¸"),
        (StageType.EXPLANATION_GENERATION, "D5: Explanation", "ğŸ“–"),
        (StageType.EVALUATION, "D7: Evaluation", "ğŸ“ˆ"),
    ]
    
    cols = st.columns(len(stage_map))
    for i, (stage_type, name, icon) in enumerate(stage_map):
        result = pipeline_result.get_stage_result(stage_type)
        with cols[i]:
            if result:
                if result.success:
                    st.metric(f"{icon}", f"{result.execution_time_ms:.0f}ms", delta="âœ…")
                else:
                    st.metric(f"{icon}", "Failed", delta="âŒ")
            else:
                st.metric(f"{icon}", "Skipped", delta="â­ï¸")
    
    total_time = pipeline_result.raw_data.get('total_execution_time_ms', 0)
    st.info(f"**Total Pipeline Execution Time:** {total_time:.0f}ms ({total_time/1000:.1f}s)")


def main():
    st.set_page_config(
        page_title="Echelon | Truth & Misinformation Detector",
        page_icon="ğŸ›¡ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    set_custom_style()
    
    # Initialize session state for chat feature
    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    if "pipeline_result_for_chat" not in st.session_state:
        st.session_state.pipeline_result_for_chat = None

    # Sidebar
    st.sidebar.title("ğŸ›¡ï¸ Echelon")
    st.sidebar.markdown("---")
    st.sidebar.subheader("Configuration")
    
    api_key = os.getenv("GOOGLE_API_KEY")
    if api_key:
        st.sidebar.success("Gemini API Key Detected âœ…")
    else:
        st.sidebar.error("API Key Missing âŒ")
        st.sidebar.info("Please set GOOGLE_API_KEY in .env")
    
    # Groq API key for chat feature
    if is_groq_available():
        st.sidebar.success("Groq API Key Detected âœ…")
    else:
        st.sidebar.warning("Groq API Key Missing âš ï¸")
        st.sidebar.info("Set GROQ_API_KEY in .env for Chat feature")

    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“‹ Pipeline Deliverables")
    st.sidebar.markdown("""
    1. **D1**: Multi-modal Input Handling
    2. **D2**: Cross-Modal Detection (CLIP)
    3. **D3**: Out-of-Context Detection
    4. **D4**: Synthetic Media Detection
    5. **D5**: Explanation Generation
    6. **D6**: Robustness Checks
    7. **D7**: Quantitative Evaluation
    """)

    # Main Content
    st.title("ğŸ”¬ Multi-Modal Misinformation Detection")
    st.markdown("### Verify claims with AI-powered cross-modal analysis pipeline")
    st.markdown("---")

    col1, col2 = st.columns([1, 1], gap="large")

    with col1:
        st.header("1. Upload Evidence")
        uploaded_file = st.file_uploader("Upload Image or Video", type=["jpg", "jpeg", "png", "mp4"])
        
        image = None
        if uploaded_file is not None:
            file_type = uploaded_file.type.split('/')[0]
            if file_type == "image":
                image = Image.open(uploaded_file).convert("RGB")
                st.image(image, caption="Analyzed Media", use_container_width=True)
            elif file_type == "video":
                st.video(uploaded_file)
                st.info("Video upload successful. System will analyze context.")

    with col2:
        st.header("2. Claim to Verify")
        claim_text = st.text_area(
            "Enter the text/caption found with the media:",
            height=150,
            placeholder="Example: 'Breaking: Massive floods in Dubai today due to cloud seeding...'"
        )
        
        st.markdown("---")
        analyze_btn = st.button("ğŸ” Run Full Pipeline Analysis", type="primary", use_container_width=True)

    # Analysis Section
    if analyze_btn:
        if claim_text:
            st.divider()
            
            # Progress bar for pipeline stages
            progress_bar = st.progress(0, text="Initializing pipeline...")
            
            try:
                # Import the pipeline directly for detailed results
                from src.pipeline import MisinformationPipeline
                from src.pipeline.base import StageType
                
                progress_bar.progress(10, text="Loading models...")
                
                # Run the pipeline
                pipeline = MisinformationPipeline()
                pipeline_result = pipeline.run(
                    text=claim_text,
                    image=image
                )
                
                progress_bar.progress(100, text="Pipeline complete!")
                
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # TOP-LEVEL VERDICT
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                verdict = pipeline_result.verdict
                score = pipeline_result.truthfulness_score
                
                if score >= 80:
                    verdict_color = "green"
                    icon = "âœ…"
                elif score >= 50:
                    verdict_color = "orange"
                    icon = "âš ï¸"
                else:
                    verdict_color = "red"
                    icon = "ğŸš¨"

                st.markdown(f"""
                <div style="padding: 25px; border-radius: 12px; 
                            background: linear-gradient(135deg, rgba(50, 50, 50, 0.4), rgba(30, 30, 30, 0.4)); 
                            border-left: 6px solid {verdict_color}; margin: 20px 0;">
                    <h1 style="margin:0; color:{verdict_color};">{icon} VERDICT: {verdict.upper()}</h1>
                    <h3 style="margin-top:10px;">Truthfulness Score: {score}/100</h3>
                </div>
                """, unsafe_allow_html=True)
                
                # Quick summary metrics
                st.markdown("### ğŸ“Š Quick Summary")
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("Cross-Modal", f"{pipeline_result.cross_modal_score:.3f}")
                with col2:
                    st.metric("AI Text", f"{pipeline_result.ai_text_probability:.1%}")
                with col3:
                    st.metric("AI Image", f"{pipeline_result.ai_image_probability:.1%}")
                with col4:
                    # Get deepfake probability from raw data
                    deepfake_prob = pipeline_result.raw_data.get('stage_results', {}).get('synthetic_detection', {}).get('deepfake_probability', 0)
                    st.metric("Deepfake", f"{deepfake_prob:.1%}")
                with col5:
                    st.metric("Robustness", f"{pipeline_result.robustness_score:.1%}")
                
                # Display detailed results for each deliverable
                display_deliverable_results(pipeline_result, has_image=(image is not None))
                
                # Raw data expander
                with st.expander("ğŸ”§ View Raw Pipeline Data"):
                    st.json(pipeline_result.to_dict())
                
                # Store pipeline result in session state for chat feature
                st.session_state.pipeline_result_for_chat = pipeline_result.to_dict()
                # Clear previous chat when new analysis is run
                st.session_state.chat_messages = []
                    
            except Exception as e:
                progress_bar.empty()
                st.error(f"Pipeline Failed: {str(e)}")
                import traceback
                st.code(traceback.format_exc())

        else:
            st.warning("Please enter a claim to verify.")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CHAT WITH EVIDENCE FEATURE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if st.session_state.pipeline_result_for_chat is not None:
        st.markdown("---")
        st.markdown("## ğŸ’¬ Chat with Evidence")
        st.markdown("*Ask follow-up questions about the analysis results*")
        
        # Check if Groq is available
        if not is_groq_available():
            st.warning("âš ï¸ **Chat feature unavailable**: Please set `GROQ_API_KEY` in your `.env` file to enable the Chat with Evidence feature.")
        else:
            # Display existing chat messages
            for message in st.session_state.chat_messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            # Chat input
            if prompt := st.chat_input("Ask about the analysis (e.g., 'Why is this considered fake?', 'What evidence supports this verdict?')"):
                # Add user message to history
                st.session_state.chat_messages.append({"role": "user", "content": prompt})
                
                # Display user message
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Generate AI response
                with st.chat_message("assistant"):
                    with st.spinner("Analyzing evidence..."):
                        try:
                            # Get response from Groq
                            response = get_chat_response(
                                messages=st.session_state.chat_messages,
                                pipeline_result=st.session_state.pipeline_result_for_chat
                            )
                            
                            st.markdown(response)
                            
                            # Add assistant response to history
                            st.session_state.chat_messages.append({
                                "role": "assistant",
                                "content": response
                            })
                            
                        except Exception as e:
                            error_msg = f"âŒ Error generating response: {str(e)}"
                            st.error(error_msg)
                            st.session_state.chat_messages.append({
                                "role": "assistant",
                                "content": error_msg
                            })
            
            # Clear chat button
            if st.session_state.chat_messages:
                if st.button("ğŸ—‘ï¸ Clear Chat History", key="clear_chat"):
                    st.session_state.chat_messages = []
                    st.rerun()

if __name__ == "__main__":
    main()
